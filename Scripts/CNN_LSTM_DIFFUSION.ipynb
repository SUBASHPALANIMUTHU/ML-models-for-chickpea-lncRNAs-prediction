{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "_ufO4mt66o_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TCNbJZkB66j3",
        "outputId": "f5092e2a-0f9e-4c6a-c343-8dc228240b49"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Biopython\n",
            "  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from Biopython) (1.26.4)\n",
            "Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m168.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Biopython\n",
            "Successfully installed Biopython-1.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from Bio import SeqIO\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def encode_sequence(seq, max_len=300):\n",
        "    # A, C, G, T/U encoding\n",
        "    seq = seq.upper().replace('U', 'T')\n",
        "    mapping = {'A':0, 'C':1, 'G':2, 'T':3}\n",
        "    arr = np.zeros((4, max_len), dtype=np.float32)\n",
        "    for i, base in enumerate(seq[:max_len]):\n",
        "        if base in mapping:\n",
        "            arr[mapping[base], i] = 1.0\n",
        "    return arr\n",
        "\n",
        "def gc_content(seq):\n",
        "    seq = seq.upper().replace('U','T')\n",
        "    gc = seq.count('G') + seq.count('C')\n",
        "    return gc / len(seq) if len(seq)>0 else 0\n",
        "\n",
        "def orf_length(seq):\n",
        "    start_codons = ['ATG']\n",
        "    stop_codons = ['TAA', 'TAG', 'TGA']\n",
        "    max_len = 0\n",
        "    seq = seq.upper().replace('U','T')\n",
        "    for frame in range(3):\n",
        "        for i in range(frame, len(seq)-2, 3):\n",
        "            codon = seq[i:i+3]\n",
        "            if codon in start_codons:\n",
        "                for j in range(i+3, len(seq)-2, 3):\n",
        "                    stop_codon = seq[j:j+3]\n",
        "                    if stop_codon in stop_codons:\n",
        "                        length = j+3 - i\n",
        "                        if length > max_len:\n",
        "                            max_len = length\n",
        "                        break\n",
        "    return max_len\n",
        "\n",
        "def load_fasta_encode(file, label, max_len=300):\n",
        "    seqs, labels = [], []\n",
        "    for record in SeqIO.parse(file, \"fasta\"):\n",
        "        seqs.append(encode_sequence(str(record.seq), max_len))\n",
        "        labels.append(label)\n",
        "    return seqs, labels\n",
        "\n",
        "def extract_features(sequences):\n",
        "    feats = []\n",
        "    for seq in sequences:\n",
        "        # reconstruct seq string\n",
        "        seq_str = ''.join(['ACGT'[i] if seq[i,j] == 1 else '' for j in range(seq.shape[1]) for i in range(4)])\n",
        "        gc = gc_content(seq_str)\n",
        "        orf_len = orf_length(seq_str)\n",
        "        feats.append([gc, orf_len, len(seq_str), sum(seq.flatten())])\n",
        "    return np.array(feats, dtype=np.float32)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import os\n",
        "    lnc_fasta = \"lnc_RNA_data.fa\"\n",
        "    coding_fasta = \"coding_data.fa\"\n",
        "    max_len = 300\n",
        "\n",
        "    print(\"üîç Loading lncRNA sequences...\")\n",
        "    lnc_seqs, lnc_labels = load_fasta_encode(lnc_fasta, 1, max_len)\n",
        "    print(\"üîç Loading mRNA sequences...\")\n",
        "    coding_seqs, coding_labels = load_fasta_encode(coding_fasta, 0, max_len)\n",
        "\n",
        "    X_seq = np.array(lnc_seqs + coding_seqs)\n",
        "    y = np.array(lnc_labels + coding_labels)\n",
        "\n",
        "    print(f\"‚úÖ Loaded {len(y)} sequences\")\n",
        "\n",
        "    # Extract features: GC content, ORF length, sequence length, total bases one-hot count\n",
        "    X_feat = extract_features(X_seq)\n",
        "\n",
        "    # Save numpy arrays\n",
        "    os.makedirs(\"output\", exist_ok=True)\n",
        "    np.save(\"X_seq.npy\", X_seq)\n",
        "    np.save(\"X_feat.npy\", X_feat)\n",
        "    np.save(\"y.npy\", y)\n",
        "\n",
        "    print(\"üíæ Saved X_seq.npy, X_feat.npy, y.npy \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NXcYrV6DUsf",
        "outputId": "aeea03dd-306a-41dc-d5c6-2e56790b39bc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Loading lncRNA sequences...\n",
            "üîç Loading mRNA sequences...\n",
            "‚úÖ Loaded 20000 sequences\n",
            "üíæ Saved X_seq.npy, X_feat.npy, y.npy \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4cA1TARpDXMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 03_train_diffusion_model.py (Updated with BiLSTM + Class Weights + Improved Regularization)\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ========== Device ==========\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ========== Diffusion Block ==========\n",
        "class DiffusionBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        return self.relu(out + x)\n",
        "\n",
        "# ========== Hybrid Diffusion Model ==========\n",
        "class HybridDiffusionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.seq_cnn = nn.Sequential(\n",
        "            nn.Conv1d(4, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            DiffusionBlock(64),\n",
        "            nn.Conv1d(64, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            DiffusionBlock(128),\n",
        "            nn.MaxPool1d(2)\n",
        "        )\n",
        "        self.bilstm = nn.LSTM(128, 64, batch_first=True, bidirectional=True)\n",
        "        self.feat_fc = nn.Sequential(\n",
        "            nn.Linear(4, 32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(64*2 + 32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_seq, x_feat):\n",
        "        x = self.seq_cnn(x_seq)           # [B, 128, 150]\n",
        "        x = x.permute(0, 2, 1)            # [B, 150, 128]\n",
        "        _, (h_n, _) = self.bilstm(x)      # h_n: [2, B, 64]\n",
        "        x_seq_feat = torch.cat((h_n[-2], h_n[-1]), dim=1)  # [B, 128]\n",
        "        x_feat_proj = self.feat_fc(x_feat)                 # [B, 32]\n",
        "        x = torch.cat([x_seq_feat, x_feat_proj], dim=1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# ========== Training Function ==========\n",
        "def train():\n",
        "    X_seq = np.load(\"X_seq.npy\")\n",
        "    X_feat = np.load(\"X_feat.npy\")\n",
        "    y = np.load(\"y.npy\")\n",
        "\n",
        "    X_seq = torch.tensor(X_seq, dtype=torch.float32)\n",
        "    X_feat = torch.tensor(X_feat, dtype=torch.float32)\n",
        "    y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    dataset = TensorDataset(X_seq, X_feat, y)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_set, val_set = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=64)\n",
        "\n",
        "    model = HybridDiffusionModel().to(device)\n",
        "\n",
        "    # Class weights (optional tuning based on imbalance)\n",
        "    class_counts = torch.bincount(y)\n",
        "    weights = 1.0 / class_counts.float()\n",
        "    weights = weights / weights.sum() * 2\n",
        "    criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    epochs = 50\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for x_seq_batch, x_feat_batch, label_batch in train_loader:\n",
        "            x_seq_batch = x_seq_batch.to(device)\n",
        "            x_feat_batch = x_feat_batch.to(device)\n",
        "            label_batch = label_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x_seq_batch, x_feat_batch)\n",
        "            loss = criterion(outputs, label_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch:02d} | Train Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_preds = []\n",
        "        val_labels = []\n",
        "        with torch.no_grad():\n",
        "            for x_seq_batch, x_feat_batch, label_batch in val_loader:\n",
        "                x_seq_batch = x_seq_batch.to(device)\n",
        "                x_feat_batch = x_feat_batch.to(device)\n",
        "                outputs = model(x_seq_batch, x_feat_batch)\n",
        "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "                val_preds.extend(preds)\n",
        "                val_labels.extend(label_batch.numpy())\n",
        "\n",
        "        print(classification_report(val_labels, val_preds, target_names=[\"mRNA\", \"lncRNA\"]))\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(confusion_matrix(val_labels, val_preds))\n",
        "        print(f\"Accuracy: {accuracy_score(val_labels, val_preds):.4f}\\n\")\n",
        "\n",
        "    torch.save(model.state_dict(), \"hybrid_diffusion_model.pt\")\n",
        "    print(\"‚úÖ Model saved to hybrid_diffusion_model.pt\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HU4WEaJ8G8Ze",
        "outputId": "e4ecb113-c84b-43b8-eae9-abbe4ff3a9c8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train Loss: 1.1041\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.62      0.99      0.76      2005\n",
            "      lncRNA       0.96      0.40      0.57      1995\n",
            "\n",
            "    accuracy                           0.69      4000\n",
            "   macro avg       0.79      0.69      0.66      4000\n",
            "weighted avg       0.79      0.69      0.66      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1976   29]\n",
            " [1198  797]]\n",
            "Accuracy: 0.6933\n",
            "\n",
            "Epoch 02 | Train Loss: 0.5285\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.62      0.99      0.76      2005\n",
            "      lncRNA       0.97      0.40      0.56      1995\n",
            "\n",
            "    accuracy                           0.69      4000\n",
            "   macro avg       0.80      0.69      0.66      4000\n",
            "weighted avg       0.80      0.69      0.66      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1984   21]\n",
            " [1202  793]]\n",
            "Accuracy: 0.6943\n",
            "\n",
            "Epoch 03 | Train Loss: 0.5104\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.74      0.71      0.73      2005\n",
            "      lncRNA       0.72      0.75      0.74      1995\n",
            "\n",
            "    accuracy                           0.73      4000\n",
            "   macro avg       0.73      0.73      0.73      4000\n",
            "weighted avg       0.73      0.73      0.73      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1423  582]\n",
            " [ 496 1499]]\n",
            "Accuracy: 0.7305\n",
            "\n",
            "Epoch 04 | Train Loss: 0.4976\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.77      0.66      0.71      2005\n",
            "      lncRNA       0.70      0.80      0.75      1995\n",
            "\n",
            "    accuracy                           0.73      4000\n",
            "   macro avg       0.74      0.73      0.73      4000\n",
            "weighted avg       0.74      0.73      0.73      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1322  683]\n",
            " [ 392 1603]]\n",
            "Accuracy: 0.7312\n",
            "\n",
            "Epoch 05 | Train Loss: 0.4505\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.77      0.85      0.81      2005\n",
            "      lncRNA       0.83      0.75      0.79      1995\n",
            "\n",
            "    accuracy                           0.80      4000\n",
            "   macro avg       0.80      0.80      0.80      4000\n",
            "weighted avg       0.80      0.80      0.80      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1700  305]\n",
            " [ 500 1495]]\n",
            "Accuracy: 0.7987\n",
            "\n",
            "Epoch 06 | Train Loss: 0.3928\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.83      0.87      0.85      2005\n",
            "      lncRNA       0.86      0.82      0.84      1995\n",
            "\n",
            "    accuracy                           0.85      4000\n",
            "   macro avg       0.85      0.85      0.85      4000\n",
            "weighted avg       0.85      0.85      0.85      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1743  262]\n",
            " [ 356 1639]]\n",
            "Accuracy: 0.8455\n",
            "\n",
            "Epoch 07 | Train Loss: 0.3671\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.86      0.76      0.81      2005\n",
            "      lncRNA       0.79      0.88      0.83      1995\n",
            "\n",
            "    accuracy                           0.82      4000\n",
            "   macro avg       0.82      0.82      0.82      4000\n",
            "weighted avg       0.82      0.82      0.82      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1525  480]\n",
            " [ 240 1755]]\n",
            "Accuracy: 0.8200\n",
            "\n",
            "Epoch 08 | Train Loss: 0.3235\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.84      0.88      0.86      2005\n",
            "      lncRNA       0.88      0.84      0.86      1995\n",
            "\n",
            "    accuracy                           0.86      4000\n",
            "   macro avg       0.86      0.86      0.86      4000\n",
            "weighted avg       0.86      0.86      0.86      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1772  233]\n",
            " [ 327 1668]]\n",
            "Accuracy: 0.8600\n",
            "\n",
            "Epoch 09 | Train Loss: 0.2987\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.86      0.92      0.89      2005\n",
            "      lncRNA       0.92      0.85      0.88      1995\n",
            "\n",
            "    accuracy                           0.89      4000\n",
            "   macro avg       0.89      0.89      0.89      4000\n",
            "weighted avg       0.89      0.89      0.89      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1848  157]\n",
            " [ 292 1703]]\n",
            "Accuracy: 0.8878\n",
            "\n",
            "Epoch 10 | Train Loss: 0.2829\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.84      0.94      0.89      2005\n",
            "      lncRNA       0.93      0.83      0.87      1995\n",
            "\n",
            "    accuracy                           0.88      4000\n",
            "   macro avg       0.89      0.88      0.88      4000\n",
            "weighted avg       0.89      0.88      0.88      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1883  122]\n",
            " [ 349 1646]]\n",
            "Accuracy: 0.8822\n",
            "\n",
            "Epoch 11 | Train Loss: 0.2662\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.88      0.90      0.89      2005\n",
            "      lncRNA       0.89      0.88      0.89      1995\n",
            "\n",
            "    accuracy                           0.89      4000\n",
            "   macro avg       0.89      0.89      0.89      4000\n",
            "weighted avg       0.89      0.89      0.89      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1795  210]\n",
            " [ 238 1757]]\n",
            "Accuracy: 0.8880\n",
            "\n",
            "Epoch 12 | Train Loss: 0.2591\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.87      0.93      0.90      2005\n",
            "      lncRNA       0.93      0.86      0.89      1995\n",
            "\n",
            "    accuracy                           0.90      4000\n",
            "   macro avg       0.90      0.90      0.90      4000\n",
            "weighted avg       0.90      0.90      0.90      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1867  138]\n",
            " [ 275 1720]]\n",
            "Accuracy: 0.8968\n",
            "\n",
            "Epoch 13 | Train Loss: 0.2461\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.87      0.94      0.90      2005\n",
            "      lncRNA       0.94      0.86      0.89      1995\n",
            "\n",
            "    accuracy                           0.90      4000\n",
            "   macro avg       0.90      0.90      0.90      4000\n",
            "weighted avg       0.90      0.90      0.90      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1887  118]\n",
            " [ 285 1710]]\n",
            "Accuracy: 0.8992\n",
            "\n",
            "Epoch 14 | Train Loss: 0.2407\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.82      0.97      0.89      2005\n",
            "      lncRNA       0.97      0.79      0.87      1995\n",
            "\n",
            "    accuracy                           0.88      4000\n",
            "   macro avg       0.89      0.88      0.88      4000\n",
            "weighted avg       0.89      0.88      0.88      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1952   53]\n",
            " [ 424 1571]]\n",
            "Accuracy: 0.8808\n",
            "\n",
            "Epoch 15 | Train Loss: 0.2276\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.90      0.90      0.90      2005\n",
            "      lncRNA       0.90      0.90      0.90      1995\n",
            "\n",
            "    accuracy                           0.90      4000\n",
            "   macro avg       0.90      0.90      0.90      4000\n",
            "weighted avg       0.90      0.90      0.90      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1800  205]\n",
            " [ 193 1802]]\n",
            "Accuracy: 0.9005\n",
            "\n",
            "Epoch 16 | Train Loss: 0.2204\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.90      0.92      0.91      2005\n",
            "      lncRNA       0.92      0.89      0.91      1995\n",
            "\n",
            "    accuracy                           0.91      4000\n",
            "   macro avg       0.91      0.91      0.91      4000\n",
            "weighted avg       0.91      0.91      0.91      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1845  160]\n",
            " [ 211 1784]]\n",
            "Accuracy: 0.9073\n",
            "\n",
            "Epoch 17 | Train Loss: 0.2050\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.90      0.92      0.91      2005\n",
            "      lncRNA       0.92      0.90      0.91      1995\n",
            "\n",
            "    accuracy                           0.91      4000\n",
            "   macro avg       0.91      0.91      0.91      4000\n",
            "weighted avg       0.91      0.91      0.91      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1843  162]\n",
            " [ 208 1787]]\n",
            "Accuracy: 0.9075\n",
            "\n",
            "Epoch 18 | Train Loss: 0.2023\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.89      0.93      0.91      2005\n",
            "      lncRNA       0.93      0.88      0.90      1995\n",
            "\n",
            "    accuracy                           0.91      4000\n",
            "   macro avg       0.91      0.91      0.91      4000\n",
            "weighted avg       0.91      0.91      0.91      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1872  133]\n",
            " [ 240 1755]]\n",
            "Accuracy: 0.9067\n",
            "\n",
            "Epoch 19 | Train Loss: 0.1955\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.90      0.93      0.91      2005\n",
            "      lncRNA       0.92      0.90      0.91      1995\n",
            "\n",
            "    accuracy                           0.91      4000\n",
            "   macro avg       0.91      0.91      0.91      4000\n",
            "weighted avg       0.91      0.91      0.91      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1855  150]\n",
            " [ 203 1792]]\n",
            "Accuracy: 0.9117\n",
            "\n",
            "Epoch 20 | Train Loss: 0.1819\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.91      0.92      0.91      2005\n",
            "      lncRNA       0.92      0.91      0.91      1995\n",
            "\n",
            "    accuracy                           0.91      4000\n",
            "   macro avg       0.91      0.91      0.91      4000\n",
            "weighted avg       0.91      0.91      0.91      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1840  165]\n",
            " [ 188 1807]]\n",
            "Accuracy: 0.9117\n",
            "\n",
            "Epoch 21 | Train Loss: 0.1748\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.89      0.93      0.91      2005\n",
            "      lncRNA       0.93      0.89      0.91      1995\n",
            "\n",
            "    accuracy                           0.91      4000\n",
            "   macro avg       0.91      0.91      0.91      4000\n",
            "weighted avg       0.91      0.91      0.91      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1870  135]\n",
            " [ 223 1772]]\n",
            "Accuracy: 0.9105\n",
            "\n",
            "Epoch 22 | Train Loss: 0.1620\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.86      0.96      0.91      2005\n",
            "      lncRNA       0.95      0.85      0.90      1995\n",
            "\n",
            "    accuracy                           0.90      4000\n",
            "   macro avg       0.91      0.90      0.90      4000\n",
            "weighted avg       0.91      0.90      0.90      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1924   81]\n",
            " [ 308 1687]]\n",
            "Accuracy: 0.9028\n",
            "\n",
            "Epoch 23 | Train Loss: 0.1503\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.90      0.93      0.92      2005\n",
            "      lncRNA       0.93      0.90      0.91      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1864  141]\n",
            " [ 198 1797]]\n",
            "Accuracy: 0.9153\n",
            "\n",
            "Epoch 24 | Train Loss: 0.1435\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.90      0.93      0.92      2005\n",
            "      lncRNA       0.93      0.90      0.91      1995\n",
            "\n",
            "    accuracy                           0.91      4000\n",
            "   macro avg       0.91      0.91      0.91      4000\n",
            "weighted avg       0.91      0.91      0.91      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1871  134]\n",
            " [ 209 1786]]\n",
            "Accuracy: 0.9143\n",
            "\n",
            "Epoch 25 | Train Loss: 0.1350\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.89      0.94      0.92      2005\n",
            "      lncRNA       0.94      0.89      0.91      1995\n",
            "\n",
            "    accuracy                           0.91      4000\n",
            "   macro avg       0.91      0.91      0.91      4000\n",
            "weighted avg       0.91      0.91      0.91      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1885  120]\n",
            " [ 229 1766]]\n",
            "Accuracy: 0.9127\n",
            "\n",
            "Epoch 26 | Train Loss: 0.1208\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.92      0.92      0.92      2005\n",
            "      lncRNA       0.92      0.92      0.92      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1837  168]\n",
            " [ 165 1830]]\n",
            "Accuracy: 0.9167\n",
            "\n",
            "Epoch 27 | Train Loss: 0.1092\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.90      0.94      0.92      2005\n",
            "      lncRNA       0.94      0.89      0.91      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1887  118]\n",
            " [ 220 1775]]\n",
            "Accuracy: 0.9155\n",
            "\n",
            "Epoch 28 | Train Loss: 0.1032\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.85      0.96      0.90      2005\n",
            "      lncRNA       0.96      0.83      0.89      1995\n",
            "\n",
            "    accuracy                           0.90      4000\n",
            "   macro avg       0.90      0.90      0.90      4000\n",
            "weighted avg       0.90      0.90      0.90      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1932   73]\n",
            " [ 339 1656]]\n",
            "Accuracy: 0.8970\n",
            "\n",
            "Epoch 29 | Train Loss: 0.0872\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.90      0.95      0.92      2005\n",
            "      lncRNA       0.94      0.89      0.92      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1898  107]\n",
            " [ 219 1776]]\n",
            "Accuracy: 0.9185\n",
            "\n",
            "Epoch 30 | Train Loss: 0.0755\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.91      0.93      0.92      2005\n",
            "      lncRNA       0.93      0.91      0.92      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1859  146]\n",
            " [ 173 1822]]\n",
            "Accuracy: 0.9203\n",
            "\n",
            "Epoch 31 | Train Loss: 0.0723\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.95      0.87      0.91      2005\n",
            "      lncRNA       0.88      0.95      0.91      1995\n",
            "\n",
            "    accuracy                           0.91      4000\n",
            "   macro avg       0.91      0.91      0.91      4000\n",
            "weighted avg       0.91      0.91      0.91      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1739  266]\n",
            " [  99 1896]]\n",
            "Accuracy: 0.9087\n",
            "\n",
            "Epoch 32 | Train Loss: 0.0824\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.91      0.94      0.92      2005\n",
            "      lncRNA       0.94      0.90      0.92      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1884  121]\n",
            " [ 190 1805]]\n",
            "Accuracy: 0.9223\n",
            "\n",
            "Epoch 33 | Train Loss: 0.0563\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.88      0.96      0.92      2005\n",
            "      lncRNA       0.96      0.87      0.91      1995\n",
            "\n",
            "    accuracy                           0.91      4000\n",
            "   macro avg       0.92      0.91      0.91      4000\n",
            "weighted avg       0.92      0.91      0.91      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1926   79]\n",
            " [ 267 1728]]\n",
            "Accuracy: 0.9135\n",
            "\n",
            "Epoch 34 | Train Loss: 0.0638\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.93      0.90      0.91      2005\n",
            "      lncRNA       0.90      0.93      0.92      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.91      4000\n",
            "weighted avg       0.92      0.92      0.91      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1798  207]\n",
            " [ 133 1862]]\n",
            "Accuracy: 0.9150\n",
            "\n",
            "Epoch 35 | Train Loss: 0.0525\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.93      0.90      0.92      2005\n",
            "      lncRNA       0.91      0.93      0.92      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1814  191]\n",
            " [ 137 1858]]\n",
            "Accuracy: 0.9180\n",
            "\n",
            "Epoch 36 | Train Loss: 0.0468\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.92      0.91      0.91      2005\n",
            "      lncRNA       0.91      0.92      0.91      1995\n",
            "\n",
            "    accuracy                           0.91      4000\n",
            "   macro avg       0.91      0.91      0.91      4000\n",
            "weighted avg       0.91      0.91      0.91      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1822  183]\n",
            " [ 162 1833]]\n",
            "Accuracy: 0.9137\n",
            "\n",
            "Epoch 37 | Train Loss: 0.0396\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.90      0.94      0.92      2005\n",
            "      lncRNA       0.94      0.89      0.91      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1884  121]\n",
            " [ 213 1782]]\n",
            "Accuracy: 0.9165\n",
            "\n",
            "Epoch 38 | Train Loss: 0.0419\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.90      0.93      0.92      2005\n",
            "      lncRNA       0.93      0.90      0.91      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1865  140]\n",
            " [ 197 1798]]\n",
            "Accuracy: 0.9157\n",
            "\n",
            "Epoch 39 | Train Loss: 0.0370\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.91      0.92      0.92      2005\n",
            "      lncRNA       0.92      0.91      0.92      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1851  154]\n",
            " [ 181 1814]]\n",
            "Accuracy: 0.9163\n",
            "\n",
            "Epoch 40 | Train Loss: 0.0234\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.92      0.92      0.92      2005\n",
            "      lncRNA       0.92      0.92      0.92      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1836  169]\n",
            " [ 163 1832]]\n",
            "Accuracy: 0.9170\n",
            "\n",
            "Epoch 41 | Train Loss: 0.0283\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.90      0.93      0.91      2005\n",
            "      lncRNA       0.93      0.89      0.91      1995\n",
            "\n",
            "    accuracy                           0.91      4000\n",
            "   macro avg       0.91      0.91      0.91      4000\n",
            "weighted avg       0.91      0.91      0.91      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1870  135]\n",
            " [ 217 1778]]\n",
            "Accuracy: 0.9120\n",
            "\n",
            "Epoch 42 | Train Loss: 0.0313\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.91      0.92      0.92      2005\n",
            "      lncRNA       0.92      0.91      0.92      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1846  159]\n",
            " [ 172 1823]]\n",
            "Accuracy: 0.9173\n",
            "\n",
            "Epoch 43 | Train Loss: 0.0252\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.92      0.92      0.92      2005\n",
            "      lncRNA       0.92      0.92      0.92      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1840  165]\n",
            " [ 163 1832]]\n",
            "Accuracy: 0.9180\n",
            "\n",
            "Epoch 44 | Train Loss: 0.0173\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.91      0.93      0.92      2005\n",
            "      lncRNA       0.93      0.90      0.92      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1862  143]\n",
            " [ 191 1804]]\n",
            "Accuracy: 0.9165\n",
            "\n",
            "Epoch 45 | Train Loss: 0.0238\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.93      0.89      0.91      2005\n",
            "      lncRNA       0.89      0.93      0.91      1995\n",
            "\n",
            "    accuracy                           0.91      4000\n",
            "   macro avg       0.91      0.91      0.91      4000\n",
            "weighted avg       0.91      0.91      0.91      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1787  218]\n",
            " [ 141 1854]]\n",
            "Accuracy: 0.9103\n",
            "\n",
            "Epoch 46 | Train Loss: 0.0304\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.91      0.93      0.92      2005\n",
            "      lncRNA       0.93      0.91      0.92      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1869  136]\n",
            " [ 187 1808]]\n",
            "Accuracy: 0.9193\n",
            "\n",
            "Epoch 47 | Train Loss: 0.0191\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.93      0.89      0.91      2005\n",
            "      lncRNA       0.89      0.93      0.91      1995\n",
            "\n",
            "    accuracy                           0.91      4000\n",
            "   macro avg       0.91      0.91      0.91      4000\n",
            "weighted avg       0.91      0.91      0.91      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1777  228]\n",
            " [ 134 1861]]\n",
            "Accuracy: 0.9095\n",
            "\n",
            "Epoch 48 | Train Loss: 0.0221\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.91      0.93      0.92      2005\n",
            "      lncRNA       0.93      0.91      0.92      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1867  138]\n",
            " [ 188 1807]]\n",
            "Accuracy: 0.9185\n",
            "\n",
            "Epoch 49 | Train Loss: 0.0219\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.92      0.92      0.92      2005\n",
            "      lncRNA       0.92      0.92      0.92      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1835  170]\n",
            " [ 155 1840]]\n",
            "Accuracy: 0.9187\n",
            "\n",
            "Epoch 50 | Train Loss: 0.0186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.92      0.92      0.92      2005\n",
            "      lncRNA       0.92      0.92      0.92      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1840  165]\n",
            " [ 164 1831]]\n",
            "Accuracy: 0.9177\n",
            "\n",
            "‚úÖ Model saved to hybrid_diffusion_model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 04_evaluate_diffusion_model.py\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from train_diffusion_model import HybridDiffusionModel  # assuming your training script named this way\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def evaluate():\n",
        "    # Load data\n",
        "    X_seq = np.load(\"X_seq.npy\")\n",
        "    X_feat = np.load(\"X_feat.npy\")\n",
        "    y = np.load(\"y.npy\")\n",
        "\n",
        "    X_seq = torch.tensor(X_seq, dtype=torch.float32)\n",
        "    X_feat = torch.tensor(X_feat, dtype=torch.float32)\n",
        "    y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    dataset = TensorDataset(X_seq, X_feat, y)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    _, val_set = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    val_loader = DataLoader(val_set, batch_size=64)\n",
        "\n",
        "    # Load model\n",
        "    model = HybridDiffusionModel().to(device)\n",
        "    model.load_state_dict(torch.load(\"hybrid_diffusion_model.pt\", map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_seq_batch, x_feat_batch, label_batch in val_loader:\n",
        "            x_seq_batch = x_seq_batch.to(device)\n",
        "            x_feat_batch = x_feat_batch.to(device)\n",
        "            outputs = model(x_seq_batch, x_feat_batch)\n",
        "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(label_batch.numpy())\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=[\"mRNA\", \"lncRNA\"]))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(all_labels, all_preds))\n",
        "    print(f\"Accuracy: {accuracy_score(all_labels, all_preds):.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "RE9kQDD4QqmG",
        "outputId": "5e6aea78-6699-43de-dcd9-d66a32f64ec1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'train_diffusion_model'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-f8f84a4ac084>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrain_diffusion_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHybridDiffusionModel\u001b[0m  \u001b[0;31m# assuming your training script named this way\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'train_diffusion_model'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ======= Paste model class definitions here =======\n",
        "\n",
        "class DiffusionBlock(torch.nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv = torch.nn.Conv1d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        return self.relu(out + x)\n",
        "\n",
        "class HybridDiffusionModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.seq_cnn = torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(4, 64, 3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            DiffusionBlock(64),\n",
        "            torch.nn.Conv1d(64, 128, 3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            DiffusionBlock(128),\n",
        "            torch.nn.MaxPool1d(2)\n",
        "        )\n",
        "        self.bilstm = torch.nn.LSTM(128, 64, batch_first=True, bidirectional=True)\n",
        "        self.feat_fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(4, 32),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Linear(64*2 + 32, 64),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.4),\n",
        "            torch.nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_seq, x_feat):\n",
        "        x = self.seq_cnn(x_seq)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        _, (h_n, _) = self.bilstm(x)\n",
        "        x_seq_feat = torch.cat((h_n[-2], h_n[-1]), dim=1)\n",
        "        x_feat_proj = self.feat_fc(x_feat)\n",
        "        x = torch.cat([x_seq_feat, x_feat_proj], dim=1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# ======= Evaluation function =======\n",
        "\n",
        "def evaluate():\n",
        "    # Load data\n",
        "    X_seq = np.load(\"X_seq.npy\")\n",
        "    X_feat = np.load(\"X_feat.npy\")\n",
        "    y = np.load(\"y.npy\")\n",
        "\n",
        "    X_seq = torch.tensor(X_seq, dtype=torch.float32)\n",
        "    X_feat = torch.tensor(X_feat, dtype=torch.float32)\n",
        "    y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    dataset = TensorDataset(X_seq, X_feat, y)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    _, val_set = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    val_loader = DataLoader(val_set, batch_size=64)\n",
        "\n",
        "    # Load model weights\n",
        "    model = HybridDiffusionModel().to(device)\n",
        "    model.load_state_dict(torch.load(\"hybrid_diffusion_model.pt\", map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_seq_batch, x_feat_batch, label_batch in val_loader:\n",
        "            x_seq_batch = x_seq_batch.to(device)\n",
        "            x_feat_batch = x_feat_batch.to(device)\n",
        "            outputs = model(x_seq_batch, x_feat_batch)\n",
        "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(label_batch.numpy())\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=[\"mRNA\", \"lncRNA\"]))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(all_labels, all_preds))\n",
        "    print(f\"Accuracy: {accuracy_score(all_labels, all_preds):.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD7ZOlyvQwS_",
        "outputId": "988d34dc-1c10-46af-b234-5a65ddffd273"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-6eed6583ef1e>:73: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"hybrid_diffusion_model.pt\", map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        mRNA       0.92      0.92      0.92      2005\n",
            "      lncRNA       0.92      0.92      0.92      1995\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.92      0.92      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1840  165]\n",
            " [ 164 1831]]\n",
            "Accuracy: 0.9177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from Bio import SeqIO\n",
        "import os\n",
        "\n",
        "# ========== Device ==========\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ========== Diffusion Block ==========\n",
        "class DiffusionBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        return self.relu(out + x)\n",
        "\n",
        "# ========== Hybrid Diffusion Model ==========\n",
        "class HybridDiffusionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.seq_cnn = nn.Sequential(\n",
        "            nn.Conv1d(4, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            DiffusionBlock(64),\n",
        "            nn.Conv1d(64, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            DiffusionBlock(128),\n",
        "            nn.MaxPool1d(2)\n",
        "        )\n",
        "        self.bilstm = nn.LSTM(128, 64, batch_first=True, bidirectional=True)\n",
        "        self.feat_fc = nn.Sequential(\n",
        "            nn.Linear(4, 32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(64*2 + 32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_seq, x_feat):\n",
        "        x = self.seq_cnn(x_seq)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        _, (h_n, _) = self.bilstm(x)\n",
        "        x_seq_feat = torch.cat((h_n[-2], h_n[-1]), dim=1)\n",
        "        x_feat_proj = self.feat_fc(x_feat)\n",
        "        x = torch.cat([x_seq_feat, x_feat_proj], dim=1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# ========== Feature Extraction ==========\n",
        "def one_hot_encode(seq, max_len=300):\n",
        "    mapping = {'A':0, 'C':1, 'G':2, 'U':3, 'T':3}\n",
        "    one_hot = np.zeros((4, max_len), dtype=np.float32)\n",
        "    seq = seq.upper().replace('T', 'U')\n",
        "    for i in range(min(len(seq), max_len)):\n",
        "        nt = seq[i]\n",
        "        if nt in mapping:\n",
        "            one_hot[mapping[nt], i] = 1.0\n",
        "    return one_hot\n",
        "\n",
        "def gc_content(seq):\n",
        "    seq = seq.upper()\n",
        "    gc = seq.count('G') + seq.count('C')\n",
        "    return gc / len(seq) if len(seq) > 0 else 0\n",
        "\n",
        "def orf_length(seq):\n",
        "    seq = seq.upper().replace('T', 'U')\n",
        "    start = 'AUG'\n",
        "    stops = ['UAA', 'UAG', 'UGA']\n",
        "    max_len = 0\n",
        "    for frame in range(3):\n",
        "        for i in range(frame, len(seq)-2, 3):\n",
        "            codon = seq[i:i+3]\n",
        "            if codon == start:\n",
        "                for j in range(i+3, len(seq)-2, 3):\n",
        "                    if seq[j:j+3] in stops:\n",
        "                        orf = j + 3 - i\n",
        "                        if orf > max_len:\n",
        "                            max_len = orf\n",
        "                        break\n",
        "    return max_len / len(seq) if len(seq) > 0 else 0\n",
        "\n",
        "def feature_extraction(seq):\n",
        "    gc = gc_content(seq)\n",
        "    orf = orf_length(seq)\n",
        "    length = len(seq) / 300.0  # normalize\n",
        "    at = 1 - gc\n",
        "    return np.array([gc, orf, length, at], dtype=np.float32)\n",
        "\n",
        "# ========== Prediction ==========\n",
        "def predict(fasta_path):\n",
        "    model = HybridDiffusionModel().to(device)\n",
        "    model.load_state_dict(torch.load(\"hybrid_diffusion_model.pt\", map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    seq_data, features, ids = [], [], []\n",
        "\n",
        "    for record in SeqIO.parse(fasta_path, \"fasta\"):\n",
        "        seq = str(record.seq)\n",
        "        ids.append(record.id)\n",
        "        seq_data.append(one_hot_encode(seq))\n",
        "        features.append(feature_extraction(seq))\n",
        "\n",
        "    X_seq = torch.tensor(np.array(seq_data), dtype=torch.float32).to(device)\n",
        "    X_feat = torch.tensor(np.array(features), dtype=torch.float32).to(device)\n",
        "\n",
        "    preds, probs = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(X_seq), 64):\n",
        "            s = X_seq[i:i+64]\n",
        "            f = X_feat[i:i+64]\n",
        "            out = model(s, f)\n",
        "            prob = torch.softmax(out, dim=1)[:, 1].cpu().numpy()\n",
        "            label = (prob > 0.5).astype(int)\n",
        "            preds.extend(label)\n",
        "            probs.extend(prob)\n",
        "\n",
        "    # ========== Save Results ==========\n",
        "    os.makedirs(\"output\", exist_ok=True)\n",
        "\n",
        "    # Save predictions\n",
        "    df_preds = pd.DataFrame({\n",
        "        \"ID\": ids,\n",
        "        \"Prediction\": [\"lncRNA\" if p == 1 else \"mRNA\" for p in preds],\n",
        "        \"lncRNA_Probability\": probs\n",
        "    })\n",
        "    df_preds.to_csv(\"output/predictions.csv\", index=False)\n",
        "\n",
        "    # Save features\n",
        "    df_feat = pd.DataFrame(features, columns=[\"GC_Content\", \"ORF_Length\", \"Norm_Length\", \"AT_Content\"])\n",
        "    df_feat.insert(0, \"ID\", ids)\n",
        "    df_feat.to_csv(\"output/features.csv\", index=False)\n",
        "\n",
        "    print(\"‚úÖ Prediction saved to output/predictions.csv\")\n",
        "    print(\"‚úÖ Features saved to output/features.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    predict(\"chickpea_data.fa\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kid2pcJUoJ5",
        "outputId": "27764741-3dd9-4c88-a675-14beac2ebc29"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-11f36c33042c>:98: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"hybrid_diffusion_model.pt\", map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Prediction saved to output/predictions.csv\n",
            "‚úÖ Features saved to output/features.csv\n"
          ]
        }
      ]
    }
  ]
}